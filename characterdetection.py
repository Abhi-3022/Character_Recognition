# -*- coding: utf-8 -*-
"""characterDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13-XciEIDLp17FlqRj9LOfkfpB2jr56A4
"""

import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout
from tensorflow.keras.activations import relu,sigmoid,linear
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing import image
from google.colab.patches import cv2_imshow
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image
from sklearn.preprocessing import LabelEncoder

data = pd.read_csv("/content/drive/MyDrive/archive (1)/english.csv")

"""Without Label encoder

```
# for j in range(0,len(data['label'])):
  for i in range(65,91):
    if (ascii(data['label'][j]))==('\''+chr(i)+'\''):
      data['label'][j]=i-55
for j in range(0,len(data['label'])):
  for i in range(97,123):
    if (ascii(data['label'][j]))==('\''+chr(i)+'\''):
      data['label'][j]=i-60
```
"""

data['label'][677]

x = np.array(data['image'])

x

y = data['label']
le = LabelEncoder()
y = le.fit_transform(y)

img = mpimg.imread('/content/drive/MyDrive/archive (1)/'+x[0])
imgplot = plt.imshow(img)
plt.show()

x_modified = []

for i in data['image']:
  img = Image.open('/content/drive/MyDrive/archive (1)/'+i)
  img = img.resize((64,64))
  img = img.convert('RGB')
  img = np.array(img)
  x_modified.append(img)

x_modified = np.array(x_modified)

x_scaled = x_modified/255
x_scaled.shape

x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size = 0.20)
x_train = tf.convert_to_tensor(x_train)
y_train = tf.convert_to_tensor(y_train)

model = Sequential()
model.add(Conv2D(512,kernel_size=(5,5),activation='relu',input_shape=(64,64,3)))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(256,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(256,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(512,activation='relu'))

model.add(Dense(1024,activation='relu'))

model.add(Dense(512,activation='relu'))

model.add(Dense(256,activation='relu'))

model.add(Dense(62,activation='softmax'))

model.summary()

model.compile(
    loss = 'sparse_categorical_crossentropy',
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics = ['acc']
)

history = model.fit(x_train,y_train,validation_split = 0.1,epochs = 20)

loss,accuracy = model.evaluate(x_test,y_test)
print("Test Accuracy: {}".format(accuracy))

h = history
plt.plot(h.history['loss'],label = 'Train loss')
plt.plot(h.history['val_loss'],label = 'Validation loss')
plt.legend()
plt.plot()

plt.plot(h.history['acc'],label = 'Train Accuracy')
plt.plot(h.history['val_acc'],label = 'Validation Accuracy')
plt.legend()
plt.plot()

predicted_labels = le.inverse_transform(model.predict(x_test).argmax(axis=1))
actual_labels = le.inverse_transform(y_test)

print('predicted label is ;',predicted_labels[56])
print('Actual Label is :',actual_labels[56])

img_path = input("Enter the image path : ")
inp_img = cv2.imread(img_path)
cv2_imshow(inp_img)

img = Image.open(img_path)
img = img.resize((64,64))
img = img.convert('RGB')
img = np.array(img)

#inp_img = cv2.resize(inp_img,(64,64))
inp_img = img / 255
print(inp_img.shape)
inp_img = np.reshape(inp_img,[1,64,64,3])

predicted_label = le.inverse_transform(model.predict(inp_img).argmax(axis=1))
print('predicted label is ;',predicted_label)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix


y_pred = model.predict(x_test)
y_pred_labels = np.argmax(y_pred, axis=1)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_labels)
precision = precision_score(y_test, y_pred_labels, average='weighted')
recall = recall_score(y_test, y_pred_labels, average='weighted')
f1 = f1_score(y_test, y_pred_labels, average='weighted')
confusion_mat = confusion_matrix(y_test, y_pred_labels)

# Print or use the evaluation metrics as needed
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:")
print(confusion_mat)